{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrIe0SbzRG4M32STznQl40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danikayoung16/MAT421/blob/main/Project_Plan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Plan: Developing AI Agents with LLMs\n",
        "\n",
        "### Danika Young\n",
        "\n",
        "## 1. Research Objective\n",
        "\n",
        "The goal of this project is to design and implement an AI agent powered by a Large Language Model (LLM) that can solve, explain, and verify numerical and coding problems in a step-by-step and interactive manner. This agent will be built using Python and LLM APIs such as OpenAI or DeepSeek. The project’s significance lies in demonstrating how LLMs can be adapted for educational and practical tools that go beyond static question answering—towards dynamic, human-like reasoning agents.\n",
        "\n",
        "This project also fulfills the requirements for an Honors Contract by extending the research into UI design and accessibility, making the tool user-friendly across platforms.\n",
        "\n",
        "## 2. Literature Review\n",
        "\n",
        "There has been a growing body of work focused on combining LLMs with agent frameworks, such as LangChain, AutoGPT, and BabyAGI. These agents integrate memory, tool use, and reasoning capabilities into a reusable workflow. Prior works like `SimpleMathSolverVerification.ipynb`, `mathSolverMultVerification.ipynb`, and `tradingAgent.ipynb` provide useful references on structuring LLMs for math, verification, and decision-based applications.\n",
        "\n",
        "However, few implementations focus on end-user accessibility or provide a complete pipeline from problem-solving to interactive visualization. This project fills that gap by not only developing a reasoning-capable agent but also making it usable in a web or mobile format with visual outputs.\n",
        "\n",
        "## 3. Hypothesis / Research Questions\n",
        "\n",
        "This project is driven by the following research questions:\n",
        "\n",
        "- Can a structured, prompt-based agent using LLMs reliably solve and verify complex math or code tasks?\n",
        "- Will the accuracy and explainability improve when combined with external tools (e.g., SymPy for math verification)?\n",
        "- How effective is DeepSeek compared to OpenAI in terms of performance and cost?\n",
        "- Can user engagement and understanding improve with a visual interface that clearly shows step-by-step reasoning?\n",
        "\n",
        "The underlying hypothesis is that an LLM agent with modular prompts, verification, and visual interface will outperform basic LLM chat applications in usability, accuracy, and interpretability.\n",
        "\n",
        "## 4. Methodology\n",
        "\n",
        "The project will be built in Python and follow a modular agent design:\n",
        "\n",
        "1. **Task Classification**: Classify the user input as a math problem, code issue, or verification task.\n",
        "2. **Prompt Generation**: Craft a structured prompt template dynamically, using few-shot examples.\n",
        "3. **LLM Query**: Call OpenAI or DeepSeek API for reasoning and solution generation.\n",
        "4. **Verification**: Use tools like SymPy or Python AST modules to validate the result.\n",
        "5. **Response Presentation**: Format the solution in markdown, LaTeX, or visually using MathJax/Plotly.\n",
        "\n",
        "This approach allows for flexibility, explainability, and modular extension of features such as tutoring mode or alternative agents.\n",
        "\n",
        "## 5. Data Collection\n",
        "\n",
        "### For Math Agent:\n",
        "- A curated dataset of 15–20 problems from numerical methods, calculus, and algebra textbooks.\n",
        "- Types include root-finding, differentiation, integration, and equation solving.\n",
        "- Problems will be encoded in a structured format (Markdown/JSON) for reproducibility.\n",
        "\n",
        "### For Code Debugging Agent:\n",
        "- A custom set of 10–15 Python snippets with common errors (e.g., syntax, logic, runtime).\n",
        "- Each problem will include ground truth solutions and explanations.\n",
        "\n",
        "These datasets will serve both as training/testing samples and user scenarios.\n",
        "\n",
        "## 6. Analysis Plan\n",
        "\n",
        "Analysis will focus on both **quantitative** and **qualitative** evaluation:\n",
        "\n",
        "- **Accuracy Metrics**:\n",
        "  - % of correct math solutions\n",
        "  - % of correct code fixes\n",
        "- **Explainability Score** (manual rubric):\n",
        "  - Step clarity\n",
        "  - Use of visual aids\n",
        "  - Depth of reasoning\n",
        "- **Cost/Performance**:\n",
        "  - API usage comparisons between OpenAI and DeepSeek\n",
        "- **User Feedback** *(optional)*:\n",
        "  - Short usability test (Likert scale) if UI is deployed in time\n",
        "\n",
        "Tools: Python (pandas, SymPy), Plotly for graphs, Matplotlib, custom evaluation scripts.\n",
        "\n",
        "## 7. Team Roles and Responsibilities\n",
        "\n",
        "This is an **individual project**.\n",
        "\n",
        "- **Research Design, Writing, and Implementation**: Danika Young\n",
        "- **UI and Honors Component Development**: Danika Young\n",
        "- **Experimentation and Analysis**: Danika Young\n",
        "\n",
        "All sections will be authored and submitted by the student listed above.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Honors Contract Extension: User Interface and Visualization\n",
        "\n",
        "To fulfill the Honors Contract requirement, the project will be extended to include a polished user-facing interface:\n",
        "\n",
        "### Web and Mobile Access\n",
        "\n",
        "- **Web App**: Built using Flask or FastAPI, users can input problems and receive AI-powered responses with explanations and visual breakdowns.\n",
        "- **Visual Output**:\n",
        "  - For math problems: Equation steps rendered using MathJax.\n",
        "  - For functions: Plots of functions or numerical results using Plotly.\n",
        "  - For code issues: Flowcharts or syntax trees to help users visualize errors and fixes.\n",
        "\n",
        "The UI layer enhances the project’s usability, makes the tool accessible to broader audiences, and supports real-world deployment.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "We7tjGZa7czp"
      }
    }
  ]
}